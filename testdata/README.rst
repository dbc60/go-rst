=========================================
The reStructuredText Test Data For go-rst
=========================================

These test files have been transcoded from the docutils "pseudo xml" format into standard JSON.

Some of these tests have been changed to conform to the parser and lexer provided by the go-rst package. The docutils parser
is much more complex, so some test results don't apply to the go-rst parser.

--------------------
Test Layout Overview
--------------------

Test names are serialized, the best effort was made to get the tests sorted in order of importance. Each test comes with a
unique identifier embedded in the name. Each test file begins with a number syntax formatted with "double dot quad",
`00.00.00.00`. This is to allow for incrementally adding additional variations of a single test while keeping the file names
unique.

There are currently three files per test: the rst file, the expected lexer output "items.json", and the expected parser
output "nodes.json".

Test names contain the words "good" or "bad" to indicate how the parser is expected to parse the test. Tests marked with
"good" are proper syntax and are expected to parse correctly. Tests marked with "bad" usually mean the parser is going to
generate system messages.

testdata directory layout and naming format
-------------------------------------------

::

    ▾ testdata/
        ▸ 00-test-comment/
        ▾ 01-test-paragraph/
            01.00.00.00-paragraph-good-paragraph-items.json
            01.00.00.00-paragraph-good-paragraph-nodes.json
            01.00.00.00-paragraph-good-paragraph.rst
            01.00.00.01-paragraph-good-with-line-break-items.json
            01.00.00.01-paragraph-good-with-line-break-nodes.json
            01.00.00.01-paragraph-good-with-line-break.rst
            01.00.00.02-paragraph-good-three-lines-items.json
            01.00.00.02-paragraph-good-three-lines-nodes.json
            01.00.00.02-paragraph-good-three-lines.rst
            01.00.01.00-paragraph-good-two-paragraphs-items.json
            01.00.01.00-paragraph-good-two-paragraphs-nodes.json
            01.00.01.00-paragraph-good-two-paragraphs.rst
            01.00.01.01-paragraph-good-two-paragraphs-three-lines-items.json
            01.00.01.01-paragraph-good-two-paragraphs-three-lines-nodes.json
            01.00.01.01-paragraph-good-two-paragraphs-three-lines.rst
        ▸ 02-test-inline-markup/
        ▸ 03-test-section/
        ▸ 04-test-blockquote/
        ▸ test-spec/

`01.00.01.01-paragraph-good-two-paragraphs-three-lines.rst` can be broken down in the following way:

1. The first double digit, `01` in the example indicates the group the test belongs to.

#. The second double digit, `00` indicates the first sub group of the test. There are none for the paragraph tests, but the
   inline markup tests have plenty.

#. The third double digit, `01` indicates the second sub group of the test. In the directory layout above, single paragraph
   tests belong to sub-subgroup `00` while tests with two paragraphs belong to sub-subgroup `01`.

#. The fourth and last double digit, `01` indicates the variation of the test.

#. `paragraph-good` indicates the parse is expected to produce no errors. `paragraph-bad` will produce errors, called "system
   messages" in reStructuredText.

#. `two-paragraphs-three-lines` is a short description of what the test is about.

----------
items.json
----------

The items.json files describes tokens generated by the lexer. It contains a
json array of the following object:

.. code:: json

    {
        "id": 9,
        "type": "itemInlineEmphasis",
        "text": "emphasis",
        "startPosition": 5,
        "line": 4,
        "length": 8
    }

id
  A sequential numerical identifier given to the lexed item.

type
  The type of token found by the lexer.

text
  The actual text of the token. This excludes the actual markup. For emphasized
  text written in the document as ``*emphasis``, the text would only contain
  ``emphasis``.

startPosition
  The start position in the line of the lexed token. This is the byte position
  in the line of text.

line
  The line location within the file.

length
  The actual length of the lexed token. This is the number of runes in the text
  and is not the length in bytes.

----------
nodes.json
----------

This files describes the object tree generated by the parser.

---------------
Differing Tests
---------------

1. Test: 03.02.06.01-section-bad-incomplete-sections-no-title.rst
   From: docutils/test/test_parsers/test_rst/test_section_headers.py line: 787

   The expected results by the docutils package do not make any sense at all.
   It seems the test is only to make sure the parser does not crash. So I
   modified the expected results to conform to the current output of the go-rst
   parser. Naturally the output is very different.

#. Test: 02.02.01.00-emphasis-good-emphasis-with-emphasis-apostrophe.rst
   From: docutils/test/test_parsers/test_rst/test_inline_markup.py line: 33

   Tests apostrophe handling, I think... Not really sure of the purpose of this test.
   rst2html shows the following output, which appears broken:

   .. code:: html

      <p>l'<em>emphasis</em> with the <em>emphasis</em>' apostrophe.
      lu2019*emphasis* with the <em>emphasis</em>u2019 apostrophe.</p>

#. Test: 02.00.00.00-imrr-good-double-underscore.rst
   From: http://repo.or.cz/w/docutils.git/blob/HEAD:/docutils/test/test_parsers/test_rst/test_inline_markup.py#l1594

   The markup::

     text-*separated*\u2010*by*\u2011*various*\u2012*dashes*\u2013*and*\u2014*hyphens*.
     \u00bf*punctuation*? \u00a1*examples*!\u00a0*\u00a0no-break-space\u00a0*.

   Tests recognition rules with unicode literals. \u00a0 is "No Break Space".

   Output from rst2html.py (docutils v0.12)::

     <p>text-<em>separated</em>u2010*by*u2011*various*u2012*dashes*u2013*and*u2014*hyphens*.
     u00bf*punctuation*? u00a1*examples*!u00a0*u00a0no-break-spaceu00a0*.</p>

   According to the reStructuredText spec, whitespace after an inline markup
   start string are not allowed, but this test clearly shows that it is. The
   troublesome section is ``\u00a0*\u00a0no-break-space\u00a0*`` as the parser
   cannot detect the '*' start string (based on the spec). As mentioned in the
   previous trouble item, the docutils parser does not correctly use unicode
   literals.

   I have modified this test to remove the troublesome section.
